{
  "node_id": "@n8n/n8n-nodes-langchain.embeddingsOllama",
  "name": "Embeddings Ollama",
  "version": 1,
  "semantic_context": "Use Ollama Embeddings",
  "natural_language_description": "这是 Embeddings Ollama 节点。主要用于: Use Ollama Embeddings",
  "parameters": {
    "notice": {
      "displayName": "This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>",
      "name": "notice",
      "type": "notice",
      "required": false,
      "default": "",
      "description": "",
      "natural_language_description": "参数名: This node must be connected to a vector store. <a data-action='openSelectiveNodeCreator' data-action-parameter-connectiontype='ai_vectorStore'>Insert one</a>"
    },
    "model": {
      "displayName": "Model",
      "name": "model",
      "type": "options",
      "required": true,
      "default": "llama3.2",
      "description": "The model which will generate the completion. To download models, visit Ollama Models Library.",
      "natural_language_description": "参数名: Model | 作用: The model which will generate the completion. To download models, visit Ollama Models Library. | 默认值: llama3.2 | (必填项)"
    }
  },
  "ids_manifest": {
    "role": "processor",
    "input_contract": {
      "preferred_source": "{{ $json.payload.primary }}",
      "accepts_binary": false
    },
    "output_contract": {
      "standardizer_logic": "return { payload: { primary: upstream.embeddings || upstream.embedding || upstream } }"
    }
  }
}