{
  "node_id": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
  "name": "OpenAI Chat Model",
  "version": 1,
  "semantic_context": "For advanced usage with an AI chain",
  "natural_language_description": "这是 OpenAI Chat Model 节点。主要用于: For advanced usage with an AI chain",
  "parameters": {
    "notice": {
      "displayName": "When using non-OpenAI models via \"Base URL\" override, not all models might be chat-compatible or support other features, like tools calling or JSON response format",
      "name": "notice",
      "type": "notice",
      "required": false,
      "default": "",
      "description": "",
      "natural_language_description": "参数名: When using non-OpenAI models via \"Base URL\" override, not all models might be chat-compatible or support other features, like tools calling or JSON response format"
    },
    "model": {
      "displayName": "Model",
      "name": "model",
      "type": "resourceLocator",
      "required": true,
      "default": {
        "mode": "list",
        "value": "gpt-4.1-mini"
      },
      "description": "The model. Choose from the list, or specify an ID.",
      "natural_language_description": "参数名: Model | 作用: The model. Choose from the list, or specify an ID. | 默认值: {'mode': 'list', 'value': 'gpt-4.1-mini'} | (必填项)"
    },
    "responsesApiEnabled": {
      "displayName": "Use Responses API",
      "name": "responsesApiEnabled",
      "type": "boolean",
      "required": false,
      "default": true,
      "description": "Whether to use the Responses API to generate the response. Learn more.",
      "natural_language_description": "参数名: Use Responses API | 作用: Whether to use the Responses API to generate the response. Learn more. | 默认值: True"
    },
    "builtInTools": {
      "displayName": "Built-in Tools",
      "name": "builtInTools",
      "type": "collection",
      "required": false,
      "default": {},
      "description": "",
      "natural_language_description": "参数名: Built-in Tools | 默认值: {}",
      "available_options": [
        "webSearch (值: None)",
        "fileSearch (值: None)",
        "codeInterpreter (值: None) - Whether to allow the model to execute code in a sandboxed environment"
      ]
    },
    "options": {
      "displayName": "Options",
      "name": "options",
      "type": "collection",
      "required": false,
      "default": {},
      "description": "Additional options to add",
      "natural_language_description": "参数名: Options | 作用: Additional options to add | 默认值: {}",
      "available_options": [
        "baseURL (值: None) - Override the default base URL for the API",
        "frequencyPenalty (值: None) - Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim",
        "maxTokens (值: None) - The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).",
        "responseFormat (值: None)",
        "responseFormat (值: None)",
        "textFormat (值: None)",
        "presencePenalty (值: None) - Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics",
        "temperature (值: None) - Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.",
        "reasoningEffort (值: None) - Controls the amount of reasoning tokens to use. A value of \"low\" will favor speed and economical token usage, \"high\" will favor more complete reasoning at the cost of more tokens generated and slower responses.",
        "timeout (值: None) - Maximum amount of time a request is allowed to take in milliseconds",
        "maxRetries (值: None) - Maximum number of retries to attempt",
        "topP (值: None) - Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.",
        "conversationId (值: None) - The conversation that this response belongs to. Input items and output items from this response are automatically added to this conversation after this response completes.",
        "promptCacheKey (值: None) - Used by OpenAI to cache responses for similar requests to optimize your cache hit rates",
        "safetyIdentifier (值: None) - A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user.",
        "serviceTier (值: None) - The service tier to use for the request",
        "metadata (值: None) - Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.",
        "topLogprobs (值: None) - An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability",
        "promptConfig (值: None) - Configure the reusable prompt template configured via OpenAI Dashboard. Learn more."
      ]
    }
  }
}