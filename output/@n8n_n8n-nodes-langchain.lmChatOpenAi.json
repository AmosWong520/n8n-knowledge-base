{
  "node_id": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
  "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
  "version": [
    1,
    1.1,
    1.2,
    1.3
  ],
  "semantic_context": "For advanced usage with an AI chain",
  "parameters": {
    "notice": {
      "displayName": "When using non-OpenAI models via \"Base URL\" override, not all models might be chat-compatible or support other features, like tools calling or JSON response format",
      "name": "notice",
      "type": "notice",
      "default": "",
      "displayOptions": {
        "show": {
          "/options.baseURL": [
            {
              "_cnd": {
                "exists": true
              }
            }
          ]
        }
      }
    },
    "model": {
      "displayName": "Model",
      "name": "model",
      "type": "resourceLocator",
      "default": {
        "mode": "list",
        "value": "gpt-4.1-mini"
      },
      "required": true,
      "modes": [
        {
          "displayName": "From List",
          "name": "list",
          "type": "list",
          "placeholder": "Select a model...",
          "typeOptions": {
            "searchListMethod": "searchModels",
            "searchable": true
          }
        },
        {
          "displayName": "ID",
          "name": "id",
          "type": "string",
          "placeholder": "gpt-4.1-mini"
        }
      ],
      "description": "The model. Choose from the list, or specify an ID.",
      "displayOptions": {
        "hide": {
          "@version": [
            {
              "_cnd": {
                "lte": 1.1
              }
            }
          ]
        }
      },
      "ai_hint": "The model. Choose from the list, or specify an ID."
    },
    "responsesApiEnabled": {
      "displayName": "Use Responses API",
      "name": "responsesApiEnabled",
      "type": "boolean",
      "default": true,
      "description": "Whether to use the Responses API to generate the response. <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/#use-responses-api\">Learn more</a>.",
      "displayOptions": {
        "show": {
          "@version": [
            {
              "_cnd": {
                "gte": 1.3
              }
            }
          ]
        }
      },
      "ai_hint": "布尔值：true 或 false。"
    },
    "builtInTools": {
      "displayName": "Built-in Tools",
      "name": "builtInTools",
      "placeholder": "Add Built-in Tool",
      "type": "collection",
      "default": {},
      "options": [
        {
          "displayName": "Web Search",
          "name": "webSearch",
          "type": "collection",
          "default": {
            "searchContextSize": "medium"
          },
          "options": [
            {
              "displayName": "Search Context Size",
              "name": "searchContextSize",
              "type": "options",
              "default": "medium",
              "description": "High level guidance for the amount of context window space to use for the search",
              "options": [
                {
                  "name": "Low",
                  "value": "low"
                },
                {
                  "name": "Medium",
                  "value": "medium"
                },
                {
                  "name": "High",
                  "value": "high"
                }
              ]
            },
            {
              "displayName": "Web Search Allowed Domains",
              "name": "allowedDomains",
              "type": "string",
              "default": "",
              "description": "Comma-separated list of domains to search. Only domains in this list will be searched.",
              "placeholder": "e.g. google.com, wikipedia.org"
            },
            {
              "displayName": "Country",
              "name": "country",
              "type": "string",
              "default": "",
              "placeholder": "e.g. US, GB"
            },
            {
              "displayName": "City",
              "name": "city",
              "type": "string",
              "default": "",
              "placeholder": "e.g. New York, London"
            },
            {
              "displayName": "Region",
              "name": "region",
              "type": "string",
              "default": "",
              "placeholder": "e.g. New York, London"
            }
          ]
        },
        {
          "displayName": "File Search",
          "name": "fileSearch",
          "type": "collection",
          "default": {
            "vectorStoreIds": "[]"
          },
          "options": [
            {
              "displayName": "Vector Store IDs",
              "name": "vectorStoreIds",
              "description": "The vector store IDs to use for the file search. Vector stores are managed via OpenAI Dashboard. <a href=\"https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/#built-in-tools\">Learn more</a>.",
              "type": "json",
              "default": "[]",
              "required": true
            },
            {
              "displayName": "Filters",
              "name": "filters",
              "type": "json",
              "default": "{}"
            },
            {
              "displayName": "Max Results",
              "name": "maxResults",
              "type": "number",
              "default": 1,
              "typeOptions": {
                "minValue": 1,
                "maxValue": 50
              }
            }
          ]
        },
        {
          "displayName": "Code Interpreter",
          "name": "codeInterpreter",
          "type": "boolean",
          "default": true,
          "description": "Whether to allow the model to execute code in a sandboxed environment"
        }
      ],
      "displayOptions": {
        "show": {
          "@version": [
            {
              "_cnd": {
                "gte": 1.3
              }
            }
          ],
          "/responsesApiEnabled": [
            true
          ]
        }
      },
      "ai_hint": "此参数为 fixedCollection，包含嵌套字段，不要扁平化。"
    },
    "options": {
      "displayName": "Options",
      "name": "options",
      "placeholder": "Add Option",
      "description": "Additional options to add",
      "type": "collection",
      "default": {},
      "options": [
        {
          "displayName": "Base URL",
          "name": "baseURL",
          "default": "https://api.openai.com/v1",
          "description": "Override the default base URL for the API",
          "type": "string",
          "displayOptions": {
            "hide": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.1
                  }
                }
              ]
            }
          }
        },
        {
          "displayName": "Frequency Penalty",
          "name": "frequencyPenalty",
          "default": 0,
          "typeOptions": {
            "maxValue": 2,
            "minValue": -2,
            "numberPrecision": 1
          },
          "description": "Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim",
          "type": "number"
        },
        {
          "displayName": "Maximum Number of Tokens",
          "name": "maxTokens",
          "default": -1,
          "description": "The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).",
          "type": "number",
          "typeOptions": {
            "maxValue": 32768
          }
        },
        {
          "displayName": "Response Format",
          "name": "responseFormat",
          "default": "text",
          "type": "options",
          "options": [
            {
              "name": "Text",
              "value": "text",
              "description": "Regular text response"
            },
            {
              "name": "JSON",
              "value": "json_object",
              "description": "Enables JSON mode, which should guarantee the message the model generates is valid JSON"
            }
          ],
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "lt": 1.3
                  }
                }
              ]
            }
          }
        },
        {
          "displayName": "Response Format",
          "name": "responseFormat",
          "default": "text",
          "type": "options",
          "options": [
            {
              "name": "Text",
              "value": "text",
              "description": "Regular text response"
            },
            {
              "name": "JSON",
              "value": "json_object",
              "description": "Enables JSON mode, which should guarantee the message the model generates is valid JSON"
            }
          ],
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.3
                  }
                }
              ],
              "/responsesApiEnabled": [
                false
              ]
            }
          }
        },
        {
          "displayName": "Response Format",
          "name": "textFormat",
          "type": "fixedCollection",
          "default": {
            "textOptions": [
              {
                "type": "text"
              }
            ]
          },
          "options": [
            {
              "displayName": "Text",
              "name": "textOptions",
              "values": [
                {
                  "displayName": "Type",
                  "name": "type",
                  "type": "options",
                  "default": "",
                  "options": [
                    {
                      "name": "Text",
                      "value": "text"
                    },
                    {
                      "name": "JSON Schema (recommended)",
                      "value": "json_schema"
                    },
                    {
                      "name": "JSON Object",
                      "value": "json_object"
                    }
                  ]
                },
                {
                  "displayName": "Verbosity",
                  "name": "verbosity",
                  "type": "options",
                  "default": "medium",
                  "options": [
                    {
                      "name": "Low",
                      "value": "low"
                    },
                    {
                      "name": "Medium",
                      "value": "medium"
                    },
                    {
                      "name": "High",
                      "value": "high"
                    }
                  ]
                },
                {
                  "displayName": "Name",
                  "name": "name",
                  "type": "string",
                  "default": "my_schema",
                  "description": "The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.",
                  "displayOptions": {
                    "show": {
                      "type": [
                        "json_schema"
                      ]
                    }
                  }
                },
                {
                  "displayName": "All properties in the schema must be set to \"required\", when using \"strict\" mode.",
                  "name": "requiredNotice",
                  "type": "notice",
                  "default": "",
                  "displayOptions": {
                    "show": {
                      "strict": [
                        true
                      ]
                    }
                  }
                },
                {
                  "displayName": "Schema",
                  "name": "schema",
                  "type": "json",
                  "default": "{\n  \"type\": \"object\",\n  \"properties\": {\n    \"message\": {\n      \"type\": \"string\"\n    }\n  },\n  \"additionalProperties\": false,\n  \"required\": [\"message\"]\n}",
                  "description": "The schema of the response format",
                  "displayOptions": {
                    "show": {
                      "type": [
                        "json_schema"
                      ]
                    }
                  }
                },
                {
                  "displayName": "Description",
                  "name": "description",
                  "type": "string",
                  "default": "",
                  "description": "The description of the response format",
                  "displayOptions": {
                    "show": {
                      "type": [
                        "json_schema"
                      ]
                    }
                  }
                },
                {
                  "displayName": "Strict",
                  "name": "strict",
                  "type": "boolean",
                  "default": false,
                  "description": "Whether to require that the AI will always generate responses that match the provided JSON Schema",
                  "displayOptions": {
                    "show": {
                      "type": [
                        "json_schema"
                      ]
                    }
                  }
                }
              ]
            }
          ],
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.3
                  }
                }
              ],
              "/responsesApiEnabled": [
                true
              ]
            }
          }
        },
        {
          "displayName": "Presence Penalty",
          "name": "presencePenalty",
          "default": 0,
          "typeOptions": {
            "maxValue": 2,
            "minValue": -2,
            "numberPrecision": 1
          },
          "description": "Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics",
          "type": "number"
        },
        {
          "displayName": "Sampling Temperature",
          "name": "temperature",
          "default": 0.7,
          "typeOptions": {
            "maxValue": 2,
            "minValue": 0,
            "numberPrecision": 1
          },
          "description": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.",
          "type": "number"
        },
        {
          "displayName": "Reasoning Effort",
          "name": "reasoningEffort",
          "default": "medium",
          "description": "Controls the amount of reasoning tokens to use. A value of \"low\" will favor speed and economical token usage, \"high\" will favor more complete reasoning at the cost of more tokens generated and slower responses.",
          "type": "options",
          "options": [
            {
              "name": "Low",
              "value": "low",
              "description": "Favors speed and economical token usage"
            },
            {
              "name": "Medium",
              "value": "medium",
              "description": "Balance between speed and reasoning accuracy"
            },
            {
              "name": "High",
              "value": "high",
              "description": "Favors more complete reasoning at the cost of more tokens generated and slower responses"
            }
          ],
          "displayOptions": {
            "show": {
              "/model": [
                {
                  "_cnd": {
                    "regex": "(^o1([-\\d]+)?$)|(^o[3-9].*)|(^gpt-5.*)"
                  }
                }
              ]
            }
          }
        },
        {
          "displayName": "Timeout",
          "name": "timeout",
          "default": 60000,
          "description": "Maximum amount of time a request is allowed to take in milliseconds",
          "type": "number"
        },
        {
          "displayName": "Max Retries",
          "name": "maxRetries",
          "default": 2,
          "description": "Maximum number of retries to attempt",
          "type": "number"
        },
        {
          "displayName": "Top P",
          "name": "topP",
          "default": 1,
          "typeOptions": {
            "maxValue": 1,
            "minValue": 0,
            "numberPrecision": 1
          },
          "description": "Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.",
          "type": "number"
        },
        {
          "displayName": "Conversation ID",
          "name": "conversationId",
          "default": "",
          "description": "The conversation that this response belongs to. Input items and output items from this response are automatically added to this conversation after this response completes.",
          "type": "string",
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.3
                  }
                }
              ],
              "/responsesApiEnabled": [
                true
              ]
            }
          }
        },
        {
          "displayName": "Prompt Cache Key",
          "name": "promptCacheKey",
          "type": "string",
          "default": "",
          "description": "Used by OpenAI to cache responses for similar requests to optimize your cache hit rates",
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.3
                  }
                }
              ],
              "/responsesApiEnabled": [
                true
              ]
            }
          }
        },
        {
          "displayName": "Safety Identifier",
          "name": "safetyIdentifier",
          "type": "string",
          "default": "",
          "description": "A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should be a string that uniquely identifies each user.",
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.3
                  }
                }
              ],
              "/responsesApiEnabled": [
                true
              ]
            }
          }
        },
        {
          "displayName": "Service Tier",
          "name": "serviceTier",
          "type": "options",
          "default": "auto",
          "description": "The service tier to use for the request",
          "options": [
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Flex",
              "value": "flex"
            },
            {
              "name": "Default",
              "value": "default"
            },
            {
              "name": "Priority",
              "value": "priority"
            }
          ],
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.3
                  }
                }
              ],
              "/responsesApiEnabled": [
                true
              ]
            }
          }
        },
        {
          "displayName": "Metadata",
          "name": "metadata",
          "type": "json",
          "description": "Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard. Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.",
          "default": "{}",
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.3
                  }
                }
              ],
              "/responsesApiEnabled": [
                true
              ]
            }
          }
        },
        {
          "displayName": "Top Logprobs",
          "name": "topLogprobs",
          "type": "number",
          "default": 0,
          "description": "An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability",
          "typeOptions": {
            "minValue": 0,
            "maxValue": 20
          },
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.3
                  }
                }
              ],
              "/responsesApiEnabled": [
                true
              ]
            }
          }
        },
        {
          "displayName": "Prompt",
          "name": "promptConfig",
          "type": "fixedCollection",
          "description": "Configure the reusable prompt template configured via OpenAI Dashboard. <a href=\"https://platform.openai.com/docs/guides/prompt-engineering#reusable-prompts\">Learn more</a>.",
          "default": {
            "promptOptions": [
              {
                "promptId": ""
              }
            ]
          },
          "options": [
            {
              "displayName": "Prompt",
              "name": "promptOptions",
              "values": [
                {
                  "displayName": "Prompt ID",
                  "name": "promptId",
                  "type": "string",
                  "default": "",
                  "description": "The unique identifier of the prompt template to use"
                },
                {
                  "displayName": "Version",
                  "name": "version",
                  "type": "string",
                  "default": "",
                  "description": "Optional version of the prompt template"
                },
                {
                  "displayName": "Variables",
                  "name": "variables",
                  "type": "json",
                  "default": "{}",
                  "description": "Variables to be substituted into the prompt template"
                }
              ]
            }
          ],
          "displayOptions": {
            "show": {
              "@version": [
                {
                  "_cnd": {
                    "gte": 1.3
                  }
                }
              ],
              "/responsesApiEnabled": [
                true
              ]
            }
          }
        }
      ],
      "ai_hint": "此参数为 fixedCollection，包含嵌套字段，不要扁平化。"
    }
  },
  "configuration_logic": {
    "required_sequence": [
      "notice",
      "notice",
      "notice",
      "model",
      "model",
      "notice",
      "responsesApiEnabled",
      "builtInTools",
      "options"
    ],
    "conditional_rules": [
      "IF /options.responseFormat == 'json_object' THEN SHOW parameter 'notice'",
      "IF /options.textFormat.textOptions.type == 'json_object' THEN SHOW parameter 'notice'",
      "IF @version == {'_cnd': {'gte': 1.2}} THEN HIDE parameter 'model'",
      "IF @version == {'_cnd': {'lte': 1.1}} THEN HIDE parameter 'model'",
      "IF /options.baseURL == {'_cnd': {'exists': True}} THEN SHOW parameter 'notice'",
      "IF @version == {'_cnd': {'gte': 1.3}} THEN SHOW parameter 'responsesApiEnabled'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == True THEN SHOW parameter 'builtInTools'",
      "IF @version == {'_cnd': {'gte': 1.1}} THEN HIDE parameter 'baseURL'",
      "IF @version == {'_cnd': {'lt': 1.3}} THEN SHOW parameter 'responseFormat'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == False THEN SHOW parameter 'responseFormat'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == True THEN SHOW parameter 'textFormat'",
      "IF type == 'json_schema' THEN SHOW parameter 'name'",
      "IF strict == True THEN SHOW parameter 'requiredNotice'",
      "IF type == 'json_schema' THEN SHOW parameter 'schema'",
      "IF type == 'json_schema' THEN SHOW parameter 'description'",
      "IF type == 'json_schema' THEN SHOW parameter 'strict'",
      "IF /model == {'_cnd': {'regex': '(^o1([-\\\\d]+)?$)|(^o[3-9].*)|(^gpt-5.*)'}} THEN SHOW parameter 'reasoningEffort'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == True THEN SHOW parameter 'conversationId'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == True THEN SHOW parameter 'promptCacheKey'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == True THEN SHOW parameter 'safetyIdentifier'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == True THEN SHOW parameter 'serviceTier'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == True THEN SHOW parameter 'metadata'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == True THEN SHOW parameter 'topLogprobs'",
      "IF @version == {'_cnd': {'gte': 1.3}} AND /responsesApiEnabled == True THEN SHOW parameter 'promptConfig'"
    ]
  }
}