{
  "node_id": "@n8n/n8n-nodes-langchain.lmCohere",
  "name": "@n8n/n8n-nodes-langchain.lmCohere",
  "version": 1,
  "semantic_context": "Language Model Cohere",
  "parameters": {
    "notice": {
      "displayName": "This node must be connected to an AI chain. <a data-action='openSelectiveNodeCreator' data-action-parameter-creatorview='AI'>Insert one</a>",
      "name": "notice",
      "type": "notice",
      "default": "",
      "typeOptions": {
        "containerClass": "ndv-connection-hint-notice"
      }
    },
    "options": {
      "displayName": "Options",
      "name": "options",
      "placeholder": "Add Option",
      "description": "Additional options to add",
      "type": "collection",
      "default": {},
      "options": [
        {
          "displayName": "Maximum Number of Tokens",
          "name": "maxTokens",
          "default": 250,
          "description": "The maximum number of tokens to generate in the completion. Most models have a context length of 2048 tokens (except for the newest models, which support 32,768).",
          "type": "number",
          "typeOptions": {
            "maxValue": 32768
          }
        },
        {
          "displayName": "Model",
          "name": "model",
          "type": "string",
          "description": "The name of the model to use",
          "default": ""
        },
        {
          "displayName": "Sampling Temperature",
          "name": "temperature",
          "default": 0,
          "typeOptions": {
            "maxValue": 1,
            "minValue": 0,
            "numberPrecision": 1
          },
          "description": "Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.",
          "type": "number"
        }
      ],
      "ai_hint": "此参数为 fixedCollection，包含嵌套字段，不要扁平化。"
    }
  },
  "configuration_logic": {
    "required_sequence": [
      "notice",
      "options"
    ],
    "conditional_rules": []
  }
}